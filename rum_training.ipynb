{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rum_training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NEk6Iu2kbVDs"},"source":["### Note: Model is trained on Colab"]},{"cell_type":"code","metadata":{"id":"6XQEEeawOVIy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625424031970,"user_tz":420,"elapsed":169,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"3854627c-5b2d-410f-b991-2fbb4e290171"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wKsd4I9tXYUg","executionInfo":{"status":"ok","timestamp":1625424033138,"user_tz":420,"elapsed":949,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["import unicodedata\n","import string\n","import re\n","import random\n","import time\n","import datetime\n","import math\n","\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch import optim\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n","import torchtext\n","\n","import spacy\n","import numpy as np\n","import pandas as pd"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GpGio1z9XNX9"},"source":["## Read data"]},{"cell_type":"code","metadata":{"id":"XHWrnNhiWOy2","executionInfo":{"status":"ok","timestamp":1625424033144,"user_tz":420,"elapsed":26,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["data_path = \"/content/drive/MyDrive/g2p/data_new/rum/\"\n","root_path = \"/content/drive/MyDrive/g2p/\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"snJAhBNAWtYI","executionInfo":{"status":"ok","timestamp":1625424033145,"user_tz":420,"elapsed":25,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["df_rum_train = pd.read_csv(data_path + \"rum_train.tsv\", sep='\\t', header=None, encoding='utf-8').rename(columns={0:\"grapheme\", 1:\"phoneme\"})\n","df_rum_dev = pd.read_csv(data_path + \"rum_dev.tsv\", sep='\\t', header=None, encoding='utf-8').rename(columns={0:\"grapheme\", 1:\"phoneme\"})\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"pJEdYomVXF22","executionInfo":{"status":"ok","timestamp":1625424033152,"user_tz":420,"elapsed":32,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"d7285cf5-fa86-4e3a-ac49-6ed488e79c7e"},"source":["df_rum_train.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>grapheme</th>\n","      <th>phoneme</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>laude</td>\n","      <td>l a u d e</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>foarte</td>\n","      <td>f o̯ a r t e</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>scoli</td>\n","      <td>s k o lʲ</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>circul</td>\n","      <td>t͡ʃ i r k u l</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>buzunar</td>\n","      <td>b u z u n a r</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  grapheme        phoneme\n","0    laude      l a u d e\n","1   foarte   f o̯ a r t e\n","2    scoli       s k o lʲ\n","3   circul  t͡ʃ i r k u l\n","4  buzunar  b u z u n a r"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"KQM2aB6Fbq6U","executionInfo":{"status":"ok","timestamp":1625424033153,"user_tz":420,"elapsed":30,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"05c461f7-e572-48a0-c045-157eeda86fc9"},"source":["df_rum_dev.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>grapheme</th>\n","      <th>phoneme</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>conduci</td>\n","      <td>k o n d u t͡ʃʲ</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>frumoase</td>\n","      <td>f r u m o̯ a s e</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>palma</td>\n","      <td>p a l m a</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>caise</td>\n","      <td>k a i s e</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>informatica</td>\n","      <td>i n f o r m a t i k a</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      grapheme                phoneme\n","0      conduci         k o n d u t͡ʃʲ\n","1     frumoase       f r u m o̯ a s e\n","2        palma              p a l m a\n","3        caise              k a i s e\n","4  informatica  i n f o r m a t i k a"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NWIIsSKabl8J","executionInfo":{"status":"ok","timestamp":1625424033154,"user_tz":420,"elapsed":29,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"95a7f980-39e4-483e-eb00-2cbf0a414778"},"source":["df_rum_train.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(700, 2)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7Yzhv2UboCC","executionInfo":{"status":"ok","timestamp":1625424033154,"user_tz":420,"elapsed":23,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"a8e4a3b2-37f1-4550-d314-d0fd683fe310"},"source":["df_rum_dev.shape"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 2)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"HYBQHeT8XPoL"},"source":["## Use torchtext to prepare data"]},{"cell_type":"code","metadata":{"id":"LZ5BMLjdXQ1o","executionInfo":{"status":"ok","timestamp":1625424033154,"user_tz":420,"elapsed":22,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["def tokenize_grapheme(text):\n","    \"\"\"\n","    Tokenizes French text from a string into a list of strings (tokens)\n","    \"\"\"\n","    return list(text)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"X8egGnCNY0S1","executionInfo":{"status":"ok","timestamp":1625424033155,"user_tz":420,"elapsed":21,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["def tokenize_phoneme(text):\n","    \"\"\"\n","    Tokenizes French text from a string into a list of strings (tokens)\n","    \"\"\"\n","    return text.split()"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PryVlCJbYS0Z","executionInfo":{"status":"ok","timestamp":1625424033376,"user_tz":420,"elapsed":241,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"4841fed6-3687-469a-960e-8e233df2554e"},"source":["df_rum_train_gra = df_rum_train[\"grapheme\"].apply(tokenize_grapheme)\n","\n","df_rum_train_gra"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                  [l, a, u, d, e]\n","1               [f, o, a, r, t, e]\n","2                  [s, c, o, l, i]\n","3               [c, i, r, c, u, l]\n","4            [b, u, z, u, n, a, r]\n","                  ...             \n","695       [d, e, l, i, c, i, o, s]\n","696                [f, o, r, m, a]\n","697                [p, r, i, m, e]\n","698          [r, e, z, u, l, t, e]\n","699    [i, n, t, e, r, v, i, n, e]\n","Name: grapheme, Length: 700, dtype: object"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A9ljOxfbYtzJ","executionInfo":{"status":"ok","timestamp":1625424033377,"user_tz":420,"elapsed":7,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"b3222290-8959-42ee-9da4-12b85c1e32f0"},"source":["df_rum_train_pho = df_rum_train[\"phoneme\"].apply(tokenize_phoneme)\n","\n","df_rum_train_pho"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                  [l, a, u, d, e]\n","1              [f, o̯, a, r, t, e]\n","2                    [s, k, o, lʲ]\n","3             [t͡ʃ, i, r, k, u, l]\n","4            [b, u, z, u, n, a, r]\n","                  ...             \n","695     [d, e, l, i, t͡ʃ, j, o, s]\n","696                [f, o, r, m, a]\n","697                [p, r, i, m, e]\n","698          [r, e, z, u, l, t, e]\n","699    [i, n, t, e, r, v, i, n, e]\n","Name: phoneme, Length: 700, dtype: object"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"VpZBPHzoXs1X","executionInfo":{"status":"ok","timestamp":1625424033377,"user_tz":420,"elapsed":4,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["SRC = torchtext.legacy.data.Field(tokenize = tokenize_grapheme, \n","            init_token = '<sos>', # since initial encoder hidden state is always set to zero, the network can figure out that the time step is 0 and this token is optional\n","            eos_token = '<eow>', \n","            lower = True)\n","TRG = torchtext.legacy.data.Field(tokenize = tokenize_phoneme, \n","            init_token = '<sow>', \n","            eos_token = '<eow>', \n","            lower = True)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rxan6AOMXtvZ","executionInfo":{"status":"ok","timestamp":1625424033378,"user_tz":420,"elapsed":5,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["assert SRC.tokenize(\"hello\") == ['h', 'e', 'l', 'l', 'o']\n","assert TRG.tokenize(\"b a b ɛ ɬ\") == ['b', 'a', 'b', 'ɛ', 'ɬ']"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"DX-RGfzoZPN1","executionInfo":{"status":"ok","timestamp":1625424033592,"user_tz":420,"elapsed":218,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["train, val = torchtext.legacy.data.TabularDataset.splits(\n","    path=data_path, train='rum_train.tsv',validation='rum_dev.tsv', \n","    format='tsv', skip_header=False, fields=[('SRC', SRC), ('TRG', TRG)])\n","\n","test = torchtext.legacy.data.TabularDataset(\n","    path=data_path + 'new_rum_test.tsv',\n","    format='tsv', skip_header=False, fields=[('SRC', SRC), ('TRG', TRG)])"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SNNnhcM4Z6NN","executionInfo":{"status":"ok","timestamp":1625424033593,"user_tz":420,"elapsed":14,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"3bf160ca-f4f0-4ad9-c030-c040fc9cb63a"},"source":["print(next(iter(train)).TRG)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["['l', 'a', 'u', 'd', 'e']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gPJEEiV2Z2gE","executionInfo":{"status":"ok","timestamp":1625424033593,"user_tz":420,"elapsed":9,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"ede8fbe3-140e-4f8b-fe82-191697b53ff7"},"source":["print(next(iter(train)).SRC)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["['l', 'a', 'u', 'd', 'e']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZN3X7cXQaFgh","executionInfo":{"status":"ok","timestamp":1625424033594,"user_tz":420,"elapsed":8,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["# build vocab\n","SRC.build_vocab(train)\n","TRG.build_vocab(train)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FniDgrl_aMEp","executionInfo":{"status":"ok","timestamp":1625424033594,"user_tz":420,"elapsed":7,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"2395391e-2219-47fb-80df-94c69908aaeb"},"source":["len(SRC.vocab)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zgCrHElvaOBe","executionInfo":{"status":"ok","timestamp":1625424033902,"user_tz":420,"elapsed":313,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"3ed2a7d0-563c-4dba-bf39-ce036b6251b9"},"source":["print(SRC.vocab.itos)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["['<unk>', '<pad>', '<sos>', '<eow>', 'e', 'i', 'a', 'r', 't', 'c', 'n', 'o', 'u', 'l', 'm', 's', 'p', 'd', 'f', 'b', 'v', 'g', 'z', 'j', 'x', 'h', 'ă', 'ț', 'y', 'â']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JeBb0WiaQPT","executionInfo":{"status":"ok","timestamp":1625424033902,"user_tz":420,"elapsed":10,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"cbdb9953-6819-48c9-abe1-3bb6be655ba9"},"source":["print(TRG.vocab.itos)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["['<unk>', '<pad>', '<sow>', '<eow>', 'a', 'e', 'i', 't', 'r', 'n', 'u', 'o', 's', 'l', 'k', 'm', 'p', 'd', 'f', 'b', 'j', 'v', 'ɡ', 'z', 't͡ʃ', 'e̯', 'ʒ', 'rʲ', 'o̯', 't͡ʃʲ', 'ʃ', 'w', 'd͡ʒ', 'iː', 'd͡ʒʲ', 'nʲ', 'zʲ', 'h', 'lʲ', 'pʲ', 'ŋ', 'ə', 'vʲ', 'kʲ', 'mʲ', 'sʲ', 't͡s', 'ɨ', 'ʃʲ']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EvXePu3QadtQ","executionInfo":{"status":"ok","timestamp":1625424033903,"user_tz":420,"elapsed":9,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"4f7e42d1-858d-44d8-97b8-a9631173caba"},"source":["print(TRG.vocab.stoi['<pad>'])"],"execution_count":22,"outputs":[{"output_type":"stream","text":["1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwCZgj5kanUK","executionInfo":{"status":"ok","timestamp":1625424033903,"user_tz":420,"elapsed":7,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"8c8bfdf5-25d7-4a40-8496-dacd83b1866f"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GDSNFXCYas3t","executionInfo":{"status":"ok","timestamp":1625424033904,"user_tz":420,"elapsed":5,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["from torchtext.legacy.data import Iterator, BucketIterator\n","train_iter = BucketIterator(\n","        train,\n","        batch_size=1,\n","        device=device,\n","        sort_key=len,\n","        shuffle=True)\n","dev_iter, test_iter = Iterator.splits(\n","        (val, test),\n","        batch_sizes=(1,1),\n","        device=device,\n","        sort=False,\n","        shuffle=False)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7puD6dzua4Mf","executionInfo":{"status":"ok","timestamp":1625424040002,"user_tz":420,"elapsed":6103,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"6cd73da5-b7d1-491f-f900-f5c1a18bdbcc"},"source":["# batch example of training data\n","for batch in train_iter:\n","    src = batch.SRC\n","    trg = batch.TRG\n","    print('tensor size of source language:', src.shape)\n","    print('tensor size of target language:', trg.shape)\n","    print('the tensor of first example in target language:', trg[:,0])\n","    break"],"execution_count":25,"outputs":[{"output_type":"stream","text":["tensor size of source language: torch.Size([10, 1])\n","tensor size of target language: torch.Size([10, 1])\n","the tensor of first example in target language: tensor([ 2, 14, 11,  9, 24,  5, 16,  7,  5,  3], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m89qb3WnbFMy"},"source":["## Build seq2seq+attention model"]},{"cell_type":"markdown","metadata":{"id":"dYcU61PwbHNt"},"source":["### Encoder"]},{"cell_type":"code","metadata":{"id":"134JX3a-bGTO","executionInfo":{"status":"ok","timestamp":1625424040002,"user_tz":420,"elapsed":5,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, enc_hid_dim, n_layers, dropout):\n","        super().__init__()\n","\n","        self.emb_dim = emb_dim\n","        self.enc_hid_dim = enc_hid_dim\n","        self.dropout = dropout\n","        self.n_layers = n_layers\n","\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.lstm = nn.LSTM(emb_dim, enc_hid_dim, n_layers, dropout=dropout, bidirectional=True)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src):\n","        \n","        #src = [src len, batch size]\n","        \n","        embedded = self.dropout(self.embedding(src))\n","        \n","        #embedded = [src len, batch size, emb dim]\n","        \n","        outputs, (hidden, cell) = self.lstm(embedded)\n","       \n","        # outputs are always from the top hidden layer, if bidirectional outputs are concatenated.\n","        # outputs = [sequence_length, batch_size, hidden_dim * num_directions]\n","        # hidden = [num_layers * num_directions, batch_size, hidden_size]\n","        # cell = [num_layers * num_directions, batch_size, hidden_size]\n","\n","        a, b, c = outputs.shape\n","        h_a, h_b, h_c = hidden.shape\n","\n","        return outputs.view(a, b, 2, -1).mean(dim=2), (hidden.view(self.n_layers, 2, h_b, h_c).mean(dim=1).squeeze(0), cell.view(self.n_layers, 2, h_b, h_c).mean(dim=1))"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oFJpxuHjbLTN"},"source":["### Attention"]},{"cell_type":"code","metadata":{"id":"LBMvEtQjbJhm","executionInfo":{"status":"ok","timestamp":1625424040003,"user_tz":420,"elapsed":5,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["class Attention(nn.Module):\n","    def __init__(self, enc_hid_dim, dec_hid_dim):\n","        super().__init__()\n","        \n","        self.W_a = nn.Linear(enc_hid_dim + dec_hid_dim, dec_hid_dim)\n","        self.v_a = nn.Parameter(torch.rand(dec_hid_dim)) # same as doing nn.Linear(dec_hid_dim, 1, bias=False)\n","        self.neg_inf = torch.tensor(-1e7, device=device)\n","        \n","    def forward(self, hidden, encoder_outputs, attention_mask):\n","        #(decoder) hidden = [batch size, dec hid dim]\n","        #encoder_outputs = [src len, batch size, enc hid dim]\n","        #attention_mask = [batch_size, src_len]\n","        \n","        batch_size = encoder_outputs.shape[1]\n","        src_len = encoder_outputs.shape[0]\n","        \n","        #repeat decoder hidden state src_len-1 times\n","        # print(\"attnetion forward encoder outputs: \", encoder_outputs.shape) # 2 x 2 x 512\n","        # print(\"attnetion forward hidden: \", hidden.shape) # 2 x 2 x 512\n","        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        \n","        #hidden = [batch size, src len, dec hid dim]\n","        #encoder_outputs = [batch size, src len, enc hid dim]\n","        \n","        # attention scoring function - part 1 - tanh(W_a[s;h])\n","        energy = torch.tanh(self.W_a(torch.cat((hidden, encoder_outputs), dim = 2))) \n","        \n","        #energy = [batch size, src len, dec hid dim]\n","        \n","        energy = energy.permute(0, 2, 1)\n","        \n","        #energy = [batch size, dec hid dim, src len]\n","        \n","        #v = [dec hid dim]\n","        \n","        v = self.v_a.repeat(batch_size, 1).unsqueeze(1)\n","        \n","        #v = [batch size, 1, dec hid dim]\n","        \n","        # attention scoring function - part 2 - v_a(tanh(W_a[s;h]))\n","        attention = torch.bmm(v, energy).squeeze(1)\n","        \n","        #attention= [batch size, src len]\n","\n","        # before computing the softmax, set attention to pad tokens to -infinity\n","        attention[attention_mask] = self.neg_inf\n","\n","        # attention scoring function - part 2 - softmax(v_a(tanh(W_a[s;h])))\n","        return F.softmax(attention, dim=1)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rY8WrCoybOJd"},"source":["### Decoder"]},{"cell_type":"code","metadata":{"id":"me39uE-FbM5U","executionInfo":{"status":"ok","timestamp":1625424040003,"user_tz":420,"elapsed":5,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, n_layers, dropout, attention):\n","        super().__init__()\n","        \n","        self.output_dim = output_dim\n","        self.attention = attention\n","        \n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        \n","        self.rnn = nn.LSTM(enc_hid_dim + emb_dim, dec_hid_dim, n_layers, dropout=dropout)\n","        \n","        self.fc_out = nn.Linear(enc_hid_dim + dec_hid_dim + emb_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden, cell, encoder_outputs, attention_mask):\n","             \n","        #input = [batch size]\n","        #hidden = [batch size, dec hid dim]\n","        #encoder_outputs = [src len, batch size, enc hid dim]\n","        #attention_mask = [batch_size, src_len]\n","        input = input.unsqueeze(0)\n","        \n","        #input = [1, batch size]\n","        \n","        embedded = self.dropout(self.embedding(input))\n","        \n","        #embedded = [1, batch size, emb dim]\n","        # get the attention probabilities\n","        attention_weights = self.attention(hidden, encoder_outputs, attention_mask)\n","                \n","        #attention_weights = [batch size, src len]\n","        \n","        attention_weights = attention_weights.unsqueeze(1)\n","        \n","        #a = [batch size, 1, src len]\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        \n","        #encoder_outputs = [batch size, src len, enc hid dim]\n","        # perform weighted sum of encoder hidden states to get attention output\n","        weighted = torch.bmm(attention_weights, encoder_outputs)\n","        \n","        #weighted = [batch size, 1, enc hid dim]\n","        \n","        weighted = weighted.permute(1, 0, 2)\n","        \n","        #weighted = [1, batch size, enc hid dim]\n","        # concatenate the attention outputs (or context vectors) with the current decoder input\n","        rnn_input = torch.cat((embedded, weighted), dim = 2)\n","        \n","        #rnn_input = [1, batch size, (enc hid dim) + emb dim]\n","        output, (hidden, cell) = self.rnn(rnn_input, (hidden.unsqueeze(0), cell))\n","        \n","        #output = [seq len, batch size, dec hid dim * n directions]\n","        #hidden = [n layers * n directions, batch size, dec hid dim]\n","        \n","        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n","        #output = [1, batch size, dec hid dim]\n","        #hidden = [1, batch size, dec hid dim]\n","        #this also means that output == hidden\n","        assert (output == hidden).all()\n","        \n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted = weighted.squeeze(0)\n","        \n","        # classification over the entire word vocabulary\n","        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n","        \n","        #prediction = [batch size, output dim]\n","        \n","        return prediction, hidden.squeeze(0), cell, attention_weights"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xCFeXKmxbQUW"},"source":["### Seq2seq with attention"]},{"cell_type":"code","metadata":{"id":"atX69QWPbPBw","executionInfo":{"status":"ok","timestamp":1625424040217,"user_tz":420,"elapsed":16,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n","        \n","        #src = [src len, batch size]\n","        #trg = [trg len, batch size]\n","        #teacher_forcing_ratio is probability to use teacher forcing\n","        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n","        batch_size = src.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","\n","        # create encoder attention mask, set attention to pad tokens to -infinity \n","        attention_mask = (src == SRC.vocab.stoi[SRC.pad_token]).transpose(0, 1)\n","        # attention_mask = [batch size, src len]\n","        \n","        #tensor to store decoder outputs\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","        # save the encoder-decoder attention weights\n","        # all_attention_weights = [batch_size, trg len-1, src len ]\n","        all_attention_weights = torch.zeros(trg.shape[1], trg.shape[0]-1, src.shape[0])\n","        #encoder_outputs is all hidden states of the input sequence, back and forwards\n","        #hidden is the final forward and backward hidden states, passed through a linear layer\n","        encoder_outputs, (hidden, cell) = self.encoder(src)\n","                \n","        #first input to the decoder is the <sos> tokens\n","        input = trg[0,:]\n","        \n","        for t in range(1, trg_len):\n","            \n","            #insert input token embedding, previous hidden state and all encoder hidden states\n","            #receive output tensor (predictions) and new hidden state\n","            output, hidden, cell, attention_weights = self.decoder(input, hidden, cell, encoder_outputs, attention_mask)\n","            \n","            # all_attention_weights[t-1] = [src len, batch size]\n","            all_attention_weights[:,t-1,:] = attention_weights.squeeze(1)\n","            \n","            #place predictions in a tensor holding predictions for each token\n","            outputs[t] = output\n","            \n","            #decide if we are going to use teacher forcing or not\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            \n","            #get the highest predicted token from our predictions\n","            top1 = output.argmax(1) \n","            \n","            #if teacher forcing, use actual next token as next input\n","            #if not, use predicted token\n","            input = trg[t] if teacher_force else top1\n","\n","        return outputs,all_attention_weights"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BeL3Dy1Ub9HM"},"source":["### Train the seq2seq model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bZgMLNl2b-S7","executionInfo":{"status":"ok","timestamp":1625424040218,"user_tz":420,"elapsed":16,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"03218b62-5a90-40a6-8c18-844a10d22ac1"},"source":["INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","\n","# hyperparameters\n","ENC_EMB_DIM = 256\n","DEC_EMB_DIM = 256\n","ENC_HID_DIM = 512\n","DEC_HID_DIM = 512\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","N_LAYERS = 1\n","LEARNING_RT = 0.001\n","\n","# model components\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attn)\n","model = Seq2Seq(enc, dec, device).to(device)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDNOZYYucBkz","executionInfo":{"status":"ok","timestamp":1625424040218,"user_tz":420,"elapsed":11,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"d5c0205b-ec3b-4524-dd70-1c9cf1b54ef1"},"source":["# weight init ## pre-trained embeddings later\n","def init_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","            \n","model.apply(init_weights)"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(30, 256)\n","    (lstm): LSTM(256, 512, dropout=0.5, bidirectional=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (attention): Attention(\n","      (W_a): Linear(in_features=1024, out_features=512, bias=True)\n","    )\n","    (embedding): Embedding(49, 256)\n","    (rnn): LSTM(768, 512, dropout=0.5)\n","    (fc_out): Linear(in_features=1280, out_features=49, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"ReCwtTvHcGM_","executionInfo":{"status":"ok","timestamp":1625424040219,"user_tz":420,"elapsed":9,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["optimizer = optim.Adam(model.parameters())"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ST-CsIOOcIKg","executionInfo":{"status":"ok","timestamp":1625424040219,"user_tz":420,"elapsed":8,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"43626a4d-4077-40c0-f61e-561dddc82fd9"},"source":["TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n","print('<pad> token index: ',TRG_PAD_IDX)\n","## we will ignore the pad token in true target set\n","criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["<pad> token index:  1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3sAzk6ZqcLFJ","executionInfo":{"status":"ok","timestamp":1625424040382,"user_tz":420,"elapsed":168,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"b5707059-cc6c-4b19-97eb-ec772e03be8d"},"source":["clip = 1\n","model.train()\n","\n","for i, batch in enumerate(train_iter):\n","\n","    src = batch.SRC\n","    trg = batch.TRG\n","    optimizer.zero_grad()\n","    output,_ = model(src, trg)\n","    #trg = [trg len, batch size]\n","    #output = [trg len, batch size, output dim]\n","\n","    output_dim = output.shape[-1]\n","\n","    output = output[1:].view(-1, output_dim)\n","    trg = trg[1:].view(-1)\n","\n","    #trg = [(trg len - 1) * batch size]\n","    #output = [(trg len - 1) * batch size, output dim]\n","\n","    loss = criterion(output, trg)\n","\n","    loss.backward()\n","\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","\n","    optimizer.step()\n","\n","    print(loss/src.shape[1])\n","    break\n","\n","    # 2, 2, 512; ==> 1, 2, 1024; <- "],"execution_count":34,"outputs":[{"output_type":"stream","text":["tensor(3.8934, device='cuda:0', grad_fn=<DivBackward0>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JxU0gLYBlFEr"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"C6yxBdRxlMJ8","executionInfo":{"status":"ok","timestamp":1625424040383,"user_tz":420,"elapsed":5,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["def train_func(model, iterator, optimizer, criterion, clip):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        src = batch.SRC\n","        trg = batch.TRG\n","        \n","        optimizer.zero_grad()\n","        \n","        output,_ = model(src, trg)\n","        \n","        #trg = [trg len, batch size]\n","        #output = [trg len, batch size, output dim]\n","        \n","        output_dim = output.shape[-1]\n","        \n","        output = output[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","        \n","        #trg = [(trg len - 1) * batch size]\n","        #output = [(trg len - 1) * batch size, output dim]\n","        \n","        loss = criterion(output, trg)\n","        \n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"xDMxhl76lNTR","executionInfo":{"status":"ok","timestamp":1625424040383,"user_tz":420,"elapsed":4,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            src = batch.SRC\n","            trg = batch.TRG\n","\n","            output,_ = model(src, trg, 0) #turn off teacher forcing\n","\n","            #trg = [trg len, batch size]\n","            #output = [trg len, batch size, output dim]\n","\n","            output_dim = output.shape[-1]\n","            \n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            #trg = [(trg len - 1) * batch size]\n","            #output = [(trg len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, trg)\n","\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"NCi4G5_JlOys","executionInfo":{"status":"ok","timestamp":1625424040384,"user_tz":420,"elapsed":5,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FTbPnG68lSPG","executionInfo":{"status":"ok","timestamp":1625424159046,"user_tz":420,"elapsed":118666,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"b1c0e0b0-417c-4716-d5da-9daf0b46e441"},"source":["N_EPOCHS = 10\n","CLIP = 1\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train_func(model, train_iter, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, dev_iter, criterion)\n","    \n","    end_time = time.time()\n","    state_dict_model = model.state_dict() \n","    state = {\n","        'epoch': epoch,\n","        'state_dict': state_dict_model,\n","        'optimizer': optimizer.state_dict()\n","        }\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    torch.save(state, root_path + \"models/rum/\" +str(epoch+1)+\".pt\")\n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f}')"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Time: 0m 11s\n","\tTrain Loss: 2.647\n","\t Val. Loss: 2.806\n","Epoch: 02 | Time: 0m 11s\n","\tTrain Loss: 2.201\n","\t Val. Loss: 1.672\n","Epoch: 03 | Time: 0m 11s\n","\tTrain Loss: 0.806\n","\t Val. Loss: 0.523\n","Epoch: 04 | Time: 0m 11s\n","\tTrain Loss: 0.347\n","\t Val. Loss: 0.346\n","Epoch: 05 | Time: 0m 11s\n","\tTrain Loss: 0.199\n","\t Val. Loss: 0.349\n","Epoch: 06 | Time: 0m 11s\n","\tTrain Loss: 0.159\n","\t Val. Loss: 0.371\n","Epoch: 07 | Time: 0m 11s\n","\tTrain Loss: 0.101\n","\t Val. Loss: 0.341\n","Epoch: 08 | Time: 0m 11s\n","\tTrain Loss: 0.091\n","\t Val. Loss: 0.390\n","Epoch: 09 | Time: 0m 11s\n","\tTrain Loss: 0.068\n","\t Val. Loss: 0.326\n","Epoch: 10 | Time: 0m 11s\n","\tTrain Loss: 0.046\n","\t Val. Loss: 0.357\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XDrDj2UfawMK"},"source":["## Evluation"]},{"cell_type":"code","metadata":{"id":"qzY8HYVClhsT","executionInfo":{"status":"ok","timestamp":1625424159047,"user_tz":420,"elapsed":19,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["def inference(model, dev_iter, src_vocab, trg_vocab, attention = True, max_trg_len = 64):\n","    '''\n","    Function for translation inference\n","\n","    Input: \n","    model: translation model;\n","    trg_vocab: Target torchtext Field\n","    attention: the model returns attention weights or not.\n","    max_trg_len: the maximal length of translation text (optinal), default = 64\n","\n","    Output:\n","    Corpus BLEU score.\n","    '''\n","    from torchtext.legacy.data import TabularDataset\n","    from torchtext.legacy.data import Iterator\n","\n","    # convert index to text string\n","    def convert_itos(convert_vocab, token_ids):\n","        list_string = []\n","        for i in token_ids:\n","            if i == convert_vocab.vocab.stoi['<eos>']:\n","                break\n","            else:\n","                token = convert_vocab.vocab.itos[i]\n","                list_string.append(token)\n","        return list_string\n","  \n","    model.eval()\n","    all_trg = []\n","    all_translated_trg = []\n","\n","    TRG_PAD_IDX = trg_vocab.vocab.stoi[trg_vocab.pad_token]\n","\n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(dev_iter):\n","\n","            src = batch.SRC\n","            #src = [src len, batch size]\n","\n","            trg = batch.TRG\n","            #trg = [trg len, batch size]\n","\n","            batch_size = trg.shape[1]\n","\n","            # create a placeholder for traget language with shape of [max_trg_len, batch_size] where all the elements are the index of <pad>. Then send to device\n","            trg_placeholder = torch.Tensor(max_trg_len, batch_size)\n","            trg_placeholder.fill_(TRG_PAD_IDX)\n","            trg_placeholder = trg_placeholder.long().to(device)\n","            if attention == True:\n","              output,_ = model(src, trg_placeholder, 0) #turn off teacher forcing\n","            else:\n","              output,_ = model(src, trg_placeholder, 0) #turn off teacher forcing\n","            # get translation results, we ignor first token <sos> in both translation and target sentences. \n","            # output_translate = [(trg len - 1), batch, output dim] output dim is size of target vocabulary.\n","            output_translate = output[1:]\n","            # store gold target sentences to a list \n","            all_trg.append(trg[1:].cpu())\n","\n","            # Choose top 1 word from decoder's output, we get the probability and index of the word\n","            prob, token_id = output_translate.data.topk(1)\n","            translation_token_id = token_id.squeeze(2).cpu()\n","\n","            # store gold target sentences to a list \n","            all_translated_trg.append(translation_token_id)\n","      \n","    all_gold_text = []\n","    all_translated_text = []\n","    for i in range(len(all_trg)): \n","        cur_gold = all_trg[i]\n","        cur_translation = all_translated_trg[i]\n","        for j in range(cur_gold.shape[1]):\n","            gold_convered_strings = convert_itos(trg_vocab,cur_gold[:,j])\n","            trans_convered_strings = convert_itos(trg_vocab,cur_translation[:,j])\n","\n","            all_gold_text.append(gold_convered_strings)\n","            all_translated_text.append(trans_convered_strings)\n","\n","    return all_gold_text, all_translated_text"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"XVIso4aIS-eV","executionInfo":{"status":"ok","timestamp":1625424159047,"user_tz":420,"elapsed":17,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["def get_validation_score(model_best, dev_iter, src_vocab, trg_vocab, out_fp):\n","  gold, translated = inference(model_best, dev_iter, src_vocab, trg_vocab, True, 64)\n","  processed_gold = []\n","  for word in gold:\n","    curr_word = []\n","    for char in word:\n","      if char != \"<eow>\" and char != \"<pad>\":\n","        curr_word.append(char)\n","    processed_gold.append(curr_word)\n","  processed_translated = []\n","  for word in translated:\n","    curr_word = []\n","    for char in word:\n","      if char == \"<eow>\":\n","        break\n","      if char != \"<eow>\":\n","        curr_word.append(char)\n","    processed_translated.append(curr_word)\n","  with open(out_fp, \"w\", encoding=\"utf-8\") as fout:\n","    for g, t in zip(processed_gold, processed_translated):\n","      fout.write(\" \".join(g) + \"\\t\" + \" \".join(t) + \"\\n\")"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XrJ29bxxZ5Uu","executionInfo":{"status":"ok","timestamp":1625424159048,"user_tz":420,"elapsed":18,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"9752d098-e679-4930-f79f-2305f92c46f8"},"source":["%cd /content/drive/MyDrive/g2p"],"execution_count":41,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/g2p\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XhUFwUbiw0j1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625424207170,"user_tz":420,"elapsed":48136,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}},"outputId":"82b4c21d-1f75-46db-9c6e-dc4f8a0454ce"},"source":["for i in range(1, 11):\n","  print(\"epoch:\", i)\n","  checkpoint = torch.load(root_path+f\"models/rum/{i}.pt\")\n","  model.load_state_dict(checkpoint['state_dict'])\n","  get_validation_score(model, dev_iter, SRC, TRG, root_path+\"evaluation/rum_gold_translated.tsv\")\n","  !python evaluate.py /content/drive/MyDrive/g2p/evaluation/rum_gold_translated.tsv"],"execution_count":42,"outputs":[{"output_type":"stream","text":["epoch: 1\n","WARNING: Incorrect prediction:\t'k o n d u t͡ʃʲ' (predicted: 'a r a a a a')\n","WARNING: Incorrect prediction:\t'f r u m o̯ a s e' (predicted: 'a u r a a a')\n","WARNING: Incorrect prediction:\t'p a l m a' (predicted: 'a u a a')\n","WARNING: Incorrect prediction:\t'k a i s e' (predicted: 'a u a a')\n","WARNING: Incorrect prediction:\t'i n f o r m a t i k a' (predicted: 'a r i t a t a t a t')\n","WARNING: Incorrect prediction:\t'a t a k' (predicted: 'a u a')\n","WARNING: Incorrect prediction:\t'e ɡ z i s t a m' (predicted: 'a r i t a t a')\n","WARNING: Incorrect prediction:\t's i m p l u' (predicted: 'a r i t a t')\n","WARNING: Incorrect prediction:\t'e k s p r i m a t' (predicted: 'a r i t a t a t')\n","WARNING: Incorrect prediction:\t'o f i t ʃ i a l' (predicted: 'a r a n i t')\n","WARNING: Incorrect prediction:\t'n e ɡ o t͡ʃ i a t' (predicted: 'a r a n i t a')\n","WARNING: Incorrect prediction:\t'r e k u n o s k u t' (predicted: 'a r a a a a a a')\n","WARNING: Incorrect prediction:\t'b a r b a' (predicted: 'a u a a')\n","WARNING: Incorrect prediction:\t'd o r m' (predicted: 'a u m e')\n","WARNING: Incorrect prediction:\t'p r i m j a w' (predicted: 'a r a a a a')\n","WARNING: Incorrect prediction:\t'k a p e t e' (predicted: 'a u r a a')\n","WARNING: Incorrect prediction:\t'p l a n t a t' (predicted: 'a u r a a a')\n","WARNING: Incorrect prediction:\t'p i k a t' (predicted: 'a r a a')\n","WARNING: Incorrect prediction:\t'a ʒ u t o r' (predicted: 'a u r a a')\n","WARNING: Incorrect prediction:\t's k r i w' (predicted: 'a r a a')\n","WARNING: Incorrect prediction:\t'p o t a b i l e' (predicted: 'a r i t a t a')\n","WARNING: Incorrect prediction:\t'd e t͡ʃ e d a t' (predicted: 'a r a a a a')\n","WARNING: Incorrect prediction:\t'a m i n t i r e' (predicted: 'a u r a a a')\n","WARNING: Incorrect prediction:\t'f a n t o m a' (predicted: 'a u r a a')\n","WARNING: Incorrect prediction:\t'm a s i v' (predicted: 'a u n a')\n","WARNING: Incorrect prediction:\t'e ɡ z i s t' (predicted: 'a r i t a')\n","WARNING: Incorrect prediction:\t'a l k o o l' (predicted: 'a u r a a')\n","WARNING: Incorrect prediction:\t'f i' (predicted: 'a')\n","WARNING: Incorrect prediction:\t'k u m v a' (predicted: 'a u a a')\n","WARNING: Incorrect prediction:\t'v a' (predicted: 'a a')\n","WARNING: Incorrect prediction:\t'b a j e' (predicted: 'a u a')\n","WARNING: Incorrect prediction:\t'k o n v i n d͡ʒ e' (predicted: 'a r a n i t a')\n","WARNING: Incorrect prediction:\t'b a t e m' (predicted: 'a u a a')\n","WARNING: Incorrect prediction:\t'm o t i v e' (predicted: 'a r i t a t')\n","WARNING: Incorrect prediction:\t'ʒ o s' (predicted: 'a a')\n","WARNING: Incorrect prediction:\t'k a n a l e' (predicted: 'a u r a a')\n","WARNING: Incorrect prediction:\t'h a j' (predicted: 'a a')\n","WARNING: Incorrect prediction:\t's u f l e t' (predicted: 'a r a a a')\n","WARNING: Incorrect prediction:\t'l u k r e z' (predicted: 'a u r a a')\n","WARNING: Incorrect prediction:\t'h e k t a r e' (predicted: 'a u r a a a')\n","WARNING: Incorrect prediction:\t's a k r i f i t͡ʃ e' (predicted: 'a r a a a a a')\n","WARNING: Incorrect prediction:\t'k r e a t' (predicted: 'a u a a')\n","WARNING: Incorrect prediction:\t'o p r e̯ a' (predicted: 'a u n a')\n","WARNING: Incorrect prediction:\t'f e r m e' (predicted: 'a u n a')\n","WARNING: Incorrect prediction:\t'b a b a' (predicted: 'a u a')\n","WARNING: Incorrect prediction:\t'k a l t͡ʃ e' (predicted: 'a u a a')\n","WARNING: Incorrect prediction:\t'k o m p l e k s e' (predicted: 'a r a t a t a')\n","WARNING: Incorrect prediction:\t't͡ʃ u d a t' (predicted: 'a u r a a')\n","WARNING: Incorrect prediction:\t'e f e k t e' (predicted: 'a r a t a')\n","WARNING: Incorrect prediction:\t'p o r n i t' (predicted: 'a r i t a')\n","WARNING: Incorrect prediction:\t'r e v i s t e' (predicted: 'a r a a a a')\n","WARNING: Incorrect prediction:\t'o k u p a m' (predicted: 'a u r a a')\n","WARNING: Incorrect prediction:\t'f e t e j' (predicted: 'a r a a')\n","WARNING: Incorrect prediction:\t'z i l n i k' (predicted: 'a r a a a')\n","WARNING: Incorrect prediction:\t'v o r b i' (predicted: 'a u m e')\n","WARNING: Incorrect prediction:\t'r e p a r a t' (predicted: 'a u r a a a')\n","WARNING: Incorrect prediction:\t'p l i k t i s i' (predicted: 'a r a n i t a')\n","WARNING: Incorrect prediction:\t'i n s p i r a t' (predicted: 'a r i t a t a t')\n","WARNING: Incorrect prediction:\t'p e r f e k t a' (predicted: 'a r a n i t a')\n","WARNING: Incorrect prediction:\t'r e v i n' (predicted: 'a u n a')\n","WARNING: Incorrect prediction:\t'd i n k o l o' (predicted: 'a r i t a t e')\n","WARNING: Incorrect prediction:\t't e m' (predicted: 'a a m')\n","WARNING: Incorrect prediction:\t'k a r' (predicted: 'a a a')\n","WARNING: Incorrect prediction:\t'd i k t a t u r a' (predicted: 'a r i t a t a t e')\n","WARNING: Incorrect prediction:\t'f u l d͡ʒʲ' (predicted: 'a u a')\n","WARNING: Incorrect prediction:\t's u k' (predicted: 'a a a')\n","WARNING: Incorrect prediction:\t'b e n zʲ' (predicted: 'a u n a')\n","WARNING: Incorrect prediction:\t'k o s t e' (predicted: 'a r a t e')\n","WARNING: Incorrect prediction:\t'r a d' (predicted: 'a a')\n","WARNING: Incorrect prediction:\t'p r i e t e n u l u j' (predicted: 'a r i t a t a t a t')\n","WARNING: Incorrect prediction:\t'j e r a w' (predicted: 'a u a')\n","WARNING: Incorrect prediction:\t'a k t͡ʃ e p t' (predicted: 'a u r a a')\n","WARNING: Incorrect prediction:\t'e ɡ z a m e n' (predicted: 'a r i t a t')\n","WARNING: Incorrect prediction:\t't r e j' (predicted: 'a r e')\n","WARNING: Incorrect prediction:\t'm u t a t' (predicted: 'a r a a')\n","WARNING: Incorrect prediction:\t'l i m b a' (predicted: 'a u n a')\n","WARNING: Incorrect prediction:\t'p l a t' (predicted: 'a u a')\n","WARNING: Incorrect prediction:\t'p r i j o r i t a t e' (predicted: 'a r i t a t a t a')\n","WARNING: Incorrect prediction:\t'k o p i j' (predicted: 'a r a a')\n","WARNING: Incorrect prediction:\t'a l e s' (predicted: 'a u a')\n","WARNING: Incorrect prediction:\t'f u s t a' (predicted: 'a u n a')\n","WARNING: Incorrect prediction:\t'k a p i t a l a' (predicted: 'a u r a a a')\n","WARNING: Incorrect prediction:\t'a m s t e r d a m' (predicted: 'a u r a a a a')\n","WARNING: Incorrect prediction:\t'v i n' (predicted: 'a a')\n","WARNING: Incorrect prediction:\t'k o m p u s e' (predicted: 'a r a a t a')\n","WARNING: Incorrect prediction:\t'r i d i k' (predicted: 'a r a a')\n","WARNING: Incorrect prediction:\t'ʒ a p o n e z' (predicted: 'a u r a a')\n","WARNING: Incorrect prediction:\t'k a u t e' (predicted: 'a u a a')\n","WARNING: Incorrect prediction:\t't e n t a t' (predicted: 'a r i t a t')\n","WARNING: Incorrect prediction:\t'd e̯ a' (predicted: 'a a a')\n","WARNING: Incorrect prediction:\t'u n d e' (predicted: 'a u a')\n","WARNING: Incorrect prediction:\t's o r i n' (predicted: 'a r i t e')\n","WARNING: Incorrect prediction:\t'f a n t a s m e' (predicted: 'a u r a a a')\n","WARNING: Incorrect prediction:\t'a r a w' (predicted: 'a u a')\n","WARNING: Incorrect prediction:\t's u f l e t e l e' (predicted: 'a r a t a t a t')\n","WARNING: Incorrect prediction:\t'p e r f e k t' (predicted: 'a r a n a t')\n","WARNING: Incorrect prediction:\t'k o n d u k' (predicted: 'a r a a a')\n","WARNING: Incorrect prediction:\t'e k s p r i mʲ' (predicted: 'a r i t a t e')\n","WARNING: Incorrect prediction:\t'd a n s a' (predicted: 'a u a a')\n","WARNING: Incorrect prediction:\t'a v e̯ a m' (predicted: 'a u a a')\n","WER:\t100.00\n","PER:\t76.90\n","epoch: 2\n","WARNING: Incorrect prediction:\t'k o n d u t͡ʃʲ' (predicted: 'k o n u n a')\n","WARNING: Incorrect prediction:\t'f r u m o̯ a s e' (predicted: 'f r u m e r e e')\n","WARNING: Incorrect prediction:\t'p a l m a' (predicted: 'p a u t a')\n","WARNING: Incorrect prediction:\t'k a i s e' (predicted: 'k a t e e')\n","WARNING: Incorrect prediction:\t'i n f o r m a t i k a' (predicted: 'i n o n o n i n a a a')\n","WARNING: Incorrect prediction:\t'a t a k' (predicted: 'a a a')\n","WARNING: Incorrect prediction:\t'e ɡ z i s t a m' (predicted: 'e m i m i t a')\n","WARNING: Incorrect prediction:\t's i m p l u' (predicted: 'i n t u r a')\n","WARNING: Incorrect prediction:\t'e k s p r i m a t' (predicted: 'e m e r i n a t e')\n","WARNING: Incorrect prediction:\t'o f i t ʃ i a l' (predicted: 'o o n i n a')\n","WARNING: Incorrect prediction:\t'n e ɡ o t͡ʃ i a t' (predicted: 'o n u n i n a t')\n","WARNING: Incorrect prediction:\t'r e k u n o s k u t' (predicted: 'p e s u n u n u n a')\n","WARNING: Incorrect prediction:\t'b a r b a' (predicted: 'f a r a a')\n","WARNING: Incorrect prediction:\t'd o r m' (predicted: 'o o r e')\n","WARNING: Incorrect prediction:\t'p r i m j a w' (predicted: 'p r i m a a a')\n","WARNING: Incorrect prediction:\t'k a p e t e' (predicted: 'k a m e t e')\n","WARNING: Incorrect prediction:\t'p l a n t a t' (predicted: 'p r a t a t a')\n","WARNING: Incorrect prediction:\t'p i k a t' (predicted: 'p i n a t')\n","WARNING: Incorrect prediction:\t'a ʒ u t o r' (predicted: 'a a u t e e')\n","WARNING: Incorrect prediction:\t's k r i w' (predicted: 's k u n')\n","WARNING: Incorrect prediction:\t'p o t a b i l e' (predicted: 'p o t a a a a e')\n","WARNING: Incorrect prediction:\t'd e t͡ʃ e d a t' (predicted: 'p e s e r a t')\n","WARNING: Incorrect prediction:\t'a m i n t i r e' (predicted: 'a t i n i n e e')\n","WARNING: Incorrect prediction:\t'f a n t o m a' (predicted: 'f a n i n a a')\n","WARNING: Incorrect prediction:\t'm a s i v' (predicted: 'm a n i n')\n","WARNING: Incorrect prediction:\t'e ɡ z i s t' (predicted: 'm i n i t e')\n","WARNING: Incorrect prediction:\t'a l k o o l' (predicted: 'a a l o n i')\n","WARNING: Incorrect prediction:\t'f i' (predicted: 'iː')\n","WARNING: Incorrect prediction:\t'k u m v a' (predicted: 'k u m a a')\n","WARNING: Incorrect prediction:\t'v a' (predicted: 'o a')\n","WARNING: Incorrect prediction:\t'b a j e' (predicted: 'f a t e')\n","WARNING: Incorrect prediction:\t'k o n v i n d͡ʒ e' (predicted: 'k o n o n i n e')\n","WARNING: Incorrect prediction:\t'b a t e m' (predicted: 'f a t e e')\n","WARNING: Incorrect prediction:\t'm o t i v e' (predicted: 'm i t i n e')\n","WARNING: Incorrect prediction:\t'ʒ o s' (predicted: 'i n t')\n","WARNING: Incorrect prediction:\t'k a n a l e' (predicted: 'k a l a r e')\n","WARNING: Incorrect prediction:\t'h a j' (predicted: 'b a')\n","WARNING: Incorrect prediction:\t's u f l e t' (predicted: 'k u l u t e')\n","WARNING: Incorrect prediction:\t'l u k r e z' (predicted: 'l u l e e')\n","WARNING: Incorrect prediction:\t'h e k t a r e' (predicted: 'p e s t a t e')\n","WARNING: Incorrect prediction:\t's a k r i f i t͡ʃ e' (predicted: 'k a l u n e r e e')\n","WARNING: Incorrect prediction:\t'o p r e̯ a' (predicted: 'o r u r a')\n","WARNING: Incorrect prediction:\t'f e r m e' (predicted: 'f e r e e')\n","WARNING: Incorrect prediction:\t'b a b a' (predicted: 'f a z a')\n","WARNING: Incorrect prediction:\t'k a l t͡ʃ e' (predicted: 'k a u r e')\n","WARNING: Incorrect prediction:\t'k o m p l e k s e' (predicted: 'k o m e r e e e')\n","WARNING: Incorrect prediction:\t't͡ʃ u d a t' (predicted: 'k i u t a t')\n","WARNING: Incorrect prediction:\t'e f e k t e' (predicted: 'e r e t e t')\n","WARNING: Incorrect prediction:\t'p o r n i t' (predicted: 'p o r o n i')\n","WARNING: Incorrect prediction:\t'r e v i s t e' (predicted: 'p e n i n t e')\n","WARNING: Incorrect prediction:\t'o k u p a m' (predicted: 'o n u r a t')\n","WARNING: Incorrect prediction:\t'f e t e j' (predicted: 'p e t e')\n","WARNING: Incorrect prediction:\t'z i l n i k' (predicted: 'o n u n i')\n","WARNING: Incorrect prediction:\t'v o r b i' (predicted: 'o o r u')\n","WARNING: Incorrect prediction:\t'r e p a r a t' (predicted: 'p e r a a a t')\n","WARNING: Incorrect prediction:\t'p l i k t i s i' (predicted: 'p u n i n i t')\n","WARNING: Incorrect prediction:\t'i n s p i r a t' (predicted: 'i n t u n i t a')\n","WARNING: Incorrect prediction:\t'p e r f e k t a' (predicted: 'p e r o n i t a')\n","WARNING: Incorrect prediction:\t'r e v i n' (predicted: 'p e n i n')\n","WARNING: Incorrect prediction:\t'd i n k o l o' (predicted: 'o n o n o n i')\n","WARNING: Incorrect prediction:\t't e m' (predicted: 't e e')\n","WARNING: Incorrect prediction:\t'k a r' (predicted: 'k a e')\n","WARNING: Incorrect prediction:\t'd i k t a t u r a' (predicted: 'o n k a t a a a a')\n","WARNING: Incorrect prediction:\t'f u l d͡ʒʲ' (predicted: 'f u z a')\n","WARNING: Incorrect prediction:\t's u k' (predicted: 'k u')\n","WARNING: Incorrect prediction:\t'b e n zʲ' (predicted: 'b e n')\n","WARNING: Incorrect prediction:\t'k o s t e' (predicted: 'o n o t e')\n","WARNING: Incorrect prediction:\t'r a d' (predicted: 'p a')\n","WARNING: Incorrect prediction:\t'p r i e t e n u l u j' (predicted: 'p r o m e r e t a t')\n","WARNING: Incorrect prediction:\t'j e r a w' (predicted: 'm r a u')\n","WARNING: Incorrect prediction:\t'a k t͡ʃ e p t' (predicted: 'a l u m e t')\n","WARNING: Incorrect prediction:\t'e ɡ z a m e n' (predicted: 'e m a m e e')\n","WARNING: Incorrect prediction:\t't r e j' (predicted: 't e e')\n","WARNING: Incorrect prediction:\t'l i m b a' (predicted: 'l i m a a')\n","WARNING: Incorrect prediction:\t'p l a t' (predicted: 'p u a t')\n","WARNING: Incorrect prediction:\t'p r i j o r i t a t e' (predicted: 'p r o n i n i t e e')\n","WARNING: Incorrect prediction:\t'k o p i j' (predicted: 'o n t͡ʃʲ')\n","WARNING: Incorrect prediction:\t'a l e s' (predicted: 'a l e e')\n","WARNING: Incorrect prediction:\t'f u s t a' (predicted: 'f u n a a')\n","WARNING: Incorrect prediction:\t'k a p i t a l a' (predicted: 'k a r i n a a a')\n","WARNING: Incorrect prediction:\t'a m s t e r d a m' (predicted: 'a t e t a t a t e')\n","WARNING: Incorrect prediction:\t'v i n' (predicted: 'o i n')\n","WARNING: Incorrect prediction:\t'k o m p u s e' (predicted: 'k o m e r e e')\n","WARNING: Incorrect prediction:\t'r i d i k' (predicted: 'p i n i')\n","WARNING: Incorrect prediction:\t'ʒ a p o n e z' (predicted: 'a a r o n e')\n","WARNING: Incorrect prediction:\t'k a u t e' (predicted: 'a a u t e')\n","WARNING: Incorrect prediction:\t't e n t a t' (predicted: 't e s t a t')\n","WARNING: Incorrect prediction:\t'd e̯ a' (predicted: 'p e̯ a')\n","WARNING: Incorrect prediction:\t'u n d e' (predicted: 'u n e e')\n","WARNING: Incorrect prediction:\t's o r i n' (predicted: 'o n o n i')\n","WARNING: Incorrect prediction:\t'f a n t a s m e' (predicted: 'f a n t a t a e')\n","WARNING: Incorrect prediction:\t'a r a w' (predicted: 'a a a r')\n","WARNING: Incorrect prediction:\t's u f l e t e l e' (predicted: 'k u l e r e r e e')\n","WARNING: Incorrect prediction:\t'p e r f e k t' (predicted: 'p e r o r i t')\n","WARNING: Incorrect prediction:\t'k o n d u k' (predicted: 'k o n u n')\n","WARNING: Incorrect prediction:\t'e k s p r i mʲ' (predicted: 'e n e r o n')\n","WARNING: Incorrect prediction:\t'd a n s a' (predicted: 'k a n a a')\n","WARNING: Incorrect prediction:\t'a v e̯ a m' (predicted: 'a l e a e')\n","WER:\t98.00\n","PER:\t50.08\n","epoch: 3\n","WARNING: Incorrect prediction:\t'f r u m o̯ a s e' (predicted: 'f r u m o̯ s s e')\n","WARNING: Incorrect prediction:\t'i n f o r m a t i k a' (predicted: 'i n f o r m a t a k a')\n","WARNING: Incorrect prediction:\t'e ɡ z i s t a m' (predicted: 'e s i s t a m e')\n","WARNING: Incorrect prediction:\t'e k s p r i m a t' (predicted: 'e k s p r i t a t')\n","WARNING: Incorrect prediction:\t'o f i t ʃ i a l' (predicted: 'o f i t͡ʃ i a l')\n","WARNING: Incorrect prediction:\t'r e k u n o s k u t' (predicted: 'r e k u n n s k k t')\n","WARNING: Incorrect prediction:\t'p r i m j a w' (predicted: 'p r i m e̯ a w')\n","WARNING: Incorrect prediction:\t'p o t a b i l e' (predicted: 'p o t a b i l l e')\n","WARNING: Incorrect prediction:\t'a m i n t i r e' (predicted: 'a m i n t r e e')\n","WARNING: Incorrect prediction:\t'm a s i v' (predicted: 'm a s i n')\n","WARNING: Incorrect prediction:\t'e ɡ z i s t' (predicted: 'e s i s t t')\n","WARNING: Incorrect prediction:\t'v a' (predicted: 'a a')\n","WARNING: Incorrect prediction:\t'k o n v i n d͡ʒ e' (predicted: 'k o n v i l e e')\n","WARNING: Incorrect prediction:\t'm o t i v e' (predicted: 'm o t i n e')\n","WARNING: Incorrect prediction:\t'ʒ o s' (predicted: 'a o s')\n","WARNING: Incorrect prediction:\t'h a j' (predicted: 'f a j')\n","WARNING: Incorrect prediction:\t's u f l e t' (predicted: 's u b l e t')\n","WARNING: Incorrect prediction:\t'l u k r e z' (predicted: 'l u t͡ʃ r e j')\n","WARNING: Incorrect prediction:\t'h e k t a r e' (predicted: 'e e t͡ʃ t a r e')\n","WARNING: Incorrect prediction:\t's a k r i f i t͡ʃ e' (predicted: 's a k r i z i t͡ʃ e')\n","WARNING: Incorrect prediction:\t'k o m p l e k s e' (predicted: 'k o m p l e s e')\n","WARNING: Incorrect prediction:\t't͡ʃ u d a t' (predicted: 't͡ʃ i u d a t')\n","WARNING: Incorrect prediction:\t'e f e k t e' (predicted: 'e z e t͡ʃ t e')\n","WARNING: Incorrect prediction:\t'v o r b i' (predicted: 'v o r b')\n","WARNING: Incorrect prediction:\t'p l i k t i s i' (predicted: 'p l i t͡ʃ t i s i')\n","WARNING: Incorrect prediction:\t'p e r f e k t a' (predicted: 'p e r f e s t a')\n","WARNING: Incorrect prediction:\t'd i k t a t u r a' (predicted: 'd i t͡ʃ t a t a r a')\n","WARNING: Incorrect prediction:\t'b e n zʲ' (predicted: 'b e n d͡ʒʲ')\n","WARNING: Incorrect prediction:\t'r a d' (predicted: 'r a w')\n","WARNING: Incorrect prediction:\t'p r i e t e n u l u j' (predicted: 'p r i e t e l u l u j')\n","WARNING: Incorrect prediction:\t'j e r a w' (predicted: 'e r e̯ a')\n","WARNING: Incorrect prediction:\t'e ɡ z a m e n' (predicted: 'e k s a m e n')\n","WARNING: Incorrect prediction:\t'p r i j o r i t a t e' (predicted: 'p r i o r i t a t e')\n","WARNING: Incorrect prediction:\t'ʒ a p o n e z' (predicted: 'a a p o n e j')\n","WARNING: Incorrect prediction:\t'e k s p r i mʲ' (predicted: 'e k s p r i m')\n","WARNING: Incorrect prediction:\t'a v e̯ a m' (predicted: 'a v e a m')\n","WER:\t36.00\n","PER:\t8.77\n","epoch: 4\n","WARNING: Incorrect prediction:\t'k a i s e' (predicted: 'k a j s e')\n","WARNING: Incorrect prediction:\t'e ɡ z i s t a m' (predicted: 'e k t͡ʃ i s t a m')\n","WARNING: Incorrect prediction:\t'o f i t ʃ i a l' (predicted: 'o f i t͡ʃ i a l')\n","WARNING: Incorrect prediction:\t'p r i m j a w' (predicted: 'p r i m e̯ a w')\n","WARNING: Incorrect prediction:\t'e ɡ z i s t' (predicted: 'e k s i s t')\n","WARNING: Incorrect prediction:\t'k o n v i n d͡ʒ e' (predicted: 'k o n v i n a')\n","WARNING: Incorrect prediction:\t'h e k t a r e' (predicted: 'h e t͡ʃ t a r e')\n","WARNING: Incorrect prediction:\t'k r e a t' (predicted: 'k r e̯ a t')\n","WARNING: Incorrect prediction:\t'k o m p l e k s e' (predicted: 'k o m p l e t͡ʃ e')\n","WARNING: Incorrect prediction:\t't͡ʃ u d a t' (predicted: 't͡ʃ j u d a t')\n","WARNING: Incorrect prediction:\t'e f e k t e' (predicted: 'e z e e t͡ʃ e')\n","WARNING: Incorrect prediction:\t'j e r a w' (predicted: 'e r e̯ a w')\n","WARNING: Incorrect prediction:\t'e ɡ z a m e n' (predicted: 'e k k a m e n')\n","WARNING: Incorrect prediction:\t'p r i j o r i t a t e' (predicted: 'p r i o r i t a t e')\n","WARNING: Incorrect prediction:\t'k o p i j' (predicted: 'k o p i i')\n","WARNING: Incorrect prediction:\t'e k s p r i mʲ' (predicted: 'e k s p r i m')\n","WER:\t16.00\n","PER:\t4.22\n","epoch: 5\n","WARNING: Incorrect prediction:\t'k a i s e' (predicted: 'k a j s e')\n","WARNING: Incorrect prediction:\t'e ɡ z i s t a m' (predicted: 'e ɡ i i s t a m')\n","WARNING: Incorrect prediction:\t'o f i t ʃ i a l' (predicted: 'o f i t͡ʃ i a l')\n","WARNING: Incorrect prediction:\t'e ɡ z i s t' (predicted: 'e ɡ i i s t')\n","WARNING: Incorrect prediction:\t'f i' (predicted: 'f iː')\n","WARNING: Incorrect prediction:\t'k o m p l e k s e' (predicted: 'k o m p l e d e')\n","WARNING: Incorrect prediction:\t't͡ʃ u d a t' (predicted: 't͡ʃ ʃ u d a t')\n","WARNING: Incorrect prediction:\t'e f e k t e' (predicted: 'e z e t͡ʃ t e')\n","WARNING: Incorrect prediction:\t'p r i e t e n u l u j' (predicted: 'p r i e t e u l u rʲ')\n","WARNING: Incorrect prediction:\t'j e r a w' (predicted: 'e r ɡ u')\n","WARNING: Incorrect prediction:\t'e ɡ z a m e n' (predicted: 'e k ɡ a m n n')\n","WARNING: Incorrect prediction:\t't r e j' (predicted: 't r e i')\n","WARNING: Incorrect prediction:\t'p r i j o r i t a t e' (predicted: 'p r i o r i t a t e')\n","WARNING: Incorrect prediction:\t'k o p i j' (predicted: 'k o p i')\n","WARNING: Incorrect prediction:\t'd e̯ a' (predicted: 'd e a')\n","WARNING: Incorrect prediction:\t'e k s p r i mʲ' (predicted: 'e k s p r i m i')\n","WARNING: Incorrect prediction:\t'a v e̯ a m' (predicted: 'a v e a m')\n","WER:\t17.00\n","PER:\t4.38\n","epoch: 6\n","WARNING: Incorrect prediction:\t'k a i s e' (predicted: 'k a j s e')\n","WARNING: Incorrect prediction:\t'e ɡ z i s t a m' (predicted: 'e m z i s t a m')\n","WARNING: Incorrect prediction:\t'e k s p r i m a t' (predicted: 'e f k s r i m a t')\n","WARNING: Incorrect prediction:\t'o f i t ʃ i a l' (predicted: 'o f i k i a l')\n","WARNING: Incorrect prediction:\t'n e ɡ o t͡ʃ i a t' (predicted: 'n e ɡ o k i a t')\n","WARNING: Incorrect prediction:\t's k r i w' (predicted: 's k r i ɡ')\n","WARNING: Incorrect prediction:\t'e ɡ z i s t' (predicted: 'e t z i s t')\n","WARNING: Incorrect prediction:\t'f i' (predicted: 'f iː')\n","WARNING: Incorrect prediction:\t'h e k t a r e' (predicted: 'd͡ʒ e k t a r e')\n","WARNING: Incorrect prediction:\t'o p r e̯ a' (predicted: 'o p r e a')\n","WARNING: Incorrect prediction:\t'k a l t͡ʃ e' (predicted: 'k a l e')\n","WARNING: Incorrect prediction:\t'k o m p l e k s e' (predicted: 'k o m p l e s e')\n","WARNING: Incorrect prediction:\t't͡ʃ u d a t' (predicted: 't͡ʃ ʃ u d a t')\n","WARNING: Incorrect prediction:\t'v o r b i' (predicted: 'v o r b')\n","WARNING: Incorrect prediction:\t'e ɡ z a m e n' (predicted: 'e f k a m e n')\n","WARNING: Incorrect prediction:\t't r e j' (predicted: 't r e i')\n","WARNING: Incorrect prediction:\t'p r i j o r i t a t e' (predicted: 'p r i o r i t a t e')\n","WARNING: Incorrect prediction:\t'k o p i j' (predicted: 'k o p i')\n","WARNING: Incorrect prediction:\t'e k s p r i mʲ' (predicted: 'e f k s r i m')\n","WER:\t19.00\n","PER:\t4.05\n","epoch: 7\n","WARNING: Incorrect prediction:\t'k a i s e' (predicted: 'k a j s e')\n","WARNING: Incorrect prediction:\t'o f i t ʃ i a l' (predicted: 'o f i t͡ʃ i a l')\n","WARNING: Incorrect prediction:\t'f i' (predicted: 'f iː')\n","WARNING: Incorrect prediction:\t'h e k t a r e' (predicted: 'd͡ʒ e k t a r e')\n","WARNING: Incorrect prediction:\t'k a l t͡ʃ e' (predicted: 'k a l e')\n","WARNING: Incorrect prediction:\t'k o m p l e k s e' (predicted: 'k o m p l e s e')\n","WARNING: Incorrect prediction:\t't͡ʃ u d a t' (predicted: 't͡ʃ i u d a t')\n","WARNING: Incorrect prediction:\t'p l i k t i s i' (predicted: 'p l i k t i s')\n","WARNING: Incorrect prediction:\t'b e n zʲ' (predicted: 'b e n d͡ʒʲ')\n","WARNING: Incorrect prediction:\t'p r i e t e n u l u j' (predicted: 'p r i e t e n u l u')\n","WARNING: Incorrect prediction:\t'j e r a w' (predicted: 'j r e̯ a')\n","WARNING: Incorrect prediction:\t'e ɡ z a m e n' (predicted: 'e k s a m e')\n","WARNING: Incorrect prediction:\t'p r i j o r i t a t e' (predicted: 'p r i o r i t a t e')\n","WARNING: Incorrect prediction:\t'k o p i j' (predicted: 'k o p i')\n","WARNING: Incorrect prediction:\t'k a u t e' (predicted: 'k a w t e')\n","WARNING: Incorrect prediction:\t's u f l e t e l e' (predicted: 's u f l e t l e')\n","WARNING: Incorrect prediction:\t'e k s p r i mʲ' (predicted: 'e k s p r i m')\n","WER:\t17.00\n","PER:\t3.71\n","epoch: 8\n","WARNING: Incorrect prediction:\t'k a i s e' (predicted: 'k a j s e')\n","WARNING: Incorrect prediction:\t'i n f o r m a t i k a' (predicted: 'i n f o r m m t i k a')\n","WARNING: Incorrect prediction:\t'e ɡ z i s t a m' (predicted: 'e m z i s t a m')\n","WARNING: Incorrect prediction:\t'e k s p r i m a t' (predicted: 'e t e p r i m a t')\n","WARNING: Incorrect prediction:\t'o f i t ʃ i a l' (predicted: 'o f i t͡ʃ j a l')\n","WARNING: Incorrect prediction:\t'n e ɡ o t͡ʃ i a t' (predicted: 'n e ɡ o t͡ʃ j a t')\n","WARNING: Incorrect prediction:\t'p i k a t' (predicted: 'p i k s a t')\n","WARNING: Incorrect prediction:\t'e ɡ z i s t' (predicted: 'e t e j s t')\n","WARNING: Incorrect prediction:\t'f i' (predicted: 'f iː')\n","WARNING: Incorrect prediction:\t'h e k t a r e' (predicted: 'd͡ʒ e k t a r e')\n","WARNING: Incorrect prediction:\t'k a l t͡ʃ e' (predicted: 'k a l e j')\n","WARNING: Incorrect prediction:\t'k o m p l e k s e' (predicted: 'k o m p l e s e')\n","WARNING: Incorrect prediction:\t't͡ʃ u d a t' (predicted: 't͡ʃ j u d a t')\n","WARNING: Incorrect prediction:\t'e f e k t e' (predicted: 'e ɡ z e t e')\n","WARNING: Incorrect prediction:\t'p r i e t e n u l u j' (predicted: 'p r i e t e n d u lʲ')\n","WARNING: Incorrect prediction:\t'e ɡ z a m e n' (predicted: 'e n z a m e n')\n","WARNING: Incorrect prediction:\t't r e j' (predicted: 't r e i')\n","WARNING: Incorrect prediction:\t'p r i j o r i t a t e' (predicted: 'p r i o r i t a t e')\n","WARNING: Incorrect prediction:\t'k o p i j' (predicted: 'k o p i')\n","WARNING: Incorrect prediction:\t'e k s p r i mʲ' (predicted: 'e j e p r i m')\n","WARNING: Incorrect prediction:\t'a v e̯ a m' (predicted: 'a v e a m')\n","WER:\t21.00\n","PER:\t5.56\n","epoch: 9\n","WARNING: Incorrect prediction:\t'k a i s e' (predicted: 'k a j s e')\n","WARNING: Incorrect prediction:\t'o f i t ʃ i a l' (predicted: 'o f i t͡ʃ i a l')\n","WARNING: Incorrect prediction:\t'f i' (predicted: 'f iː')\n","WARNING: Incorrect prediction:\t'h e k t a r e' (predicted: 'd͡ʒ e k t a r e')\n","WARNING: Incorrect prediction:\t'k a l t͡ʃ e' (predicted: 'k a l e')\n","WARNING: Incorrect prediction:\t'k o m p l e k s e' (predicted: 'k o m p l e s e')\n","WARNING: Incorrect prediction:\t't͡ʃ u d a t' (predicted: 't͡ʃ i u d a t')\n","WARNING: Incorrect prediction:\t'e f e k t e' (predicted: 'e ɡ e t͡ʃ t e')\n","WARNING: Incorrect prediction:\t'p l i k t i s i' (predicted: 'p l i k t i s sʲ')\n","WARNING: Incorrect prediction:\t'e ɡ z a m e n' (predicted: 'e k s a m e n')\n","WARNING: Incorrect prediction:\t'p r i j o r i t a t e' (predicted: 'p r i o r i t a t e')\n","WARNING: Incorrect prediction:\t'e k s p r i mʲ' (predicted: 'e k s p r i m sʲ')\n","WER:\t12.00\n","PER:\t2.70\n","epoch: 10\n","WARNING: Incorrect prediction:\t'k a i s e' (predicted: 'k a j s e')\n","WARNING: Incorrect prediction:\t'o f i t ʃ i a l' (predicted: 'o f i t͡ʃ i a l')\n","WARNING: Incorrect prediction:\t's k r i w' (predicted: 's k r i u')\n","WARNING: Incorrect prediction:\t'f i' (predicted: 'f iː')\n","WARNING: Incorrect prediction:\t'h e k t a r e' (predicted: 'd͡ʒ e k t a r e')\n","WARNING: Incorrect prediction:\t'k a l t͡ʃ e' (predicted: 'k a l e')\n","WARNING: Incorrect prediction:\t'k o m p l e k s e' (predicted: 'k o m p l e s e')\n","WARNING: Incorrect prediction:\t't͡ʃ u d a t' (predicted: 't͡ʃ i u d a t')\n","WARNING: Incorrect prediction:\t'e f e k t e' (predicted: 'e z e t͡ʃ t e')\n","WARNING: Incorrect prediction:\t'e ɡ z a m e n' (predicted: 'e k s a m e n')\n","WARNING: Incorrect prediction:\t't r e j' (predicted: 't r e i')\n","WARNING: Incorrect prediction:\t'p r i j o r i t a t e' (predicted: 'p r i o r i t a t e')\n","WARNING: Incorrect prediction:\t'k o p i j' (predicted: 'k o p i')\n","WARNING: Incorrect prediction:\t'e k s p r i mʲ' (predicted: 'e k s p r i m sʲ')\n","WER:\t14.00\n","PER:\t3.04\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EoZfvHmqa1_y"},"source":["## Prediction"]},{"cell_type":"code","metadata":{"id":"52q6v3pTxqw4","executionInfo":{"status":"ok","timestamp":1625424370181,"user_tz":420,"elapsed":4497,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["checkpoint = torch.load(root_path+f\"models/rum/9.pt\")\n","model.load_state_dict(checkpoint['state_dict'])\n","_, translated = inference(model, test_iter, SRC, TRG, True, 64)"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"WEQwtJ16CU_-","executionInfo":{"status":"ok","timestamp":1625424372510,"user_tz":420,"elapsed":194,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["def generate_final_prediction(test_file_path, translated, output_file_path):\n","  '''\n","  test_file_path -- the file path to the test file\n","  translated -- a list of lists that contain predictions\n","  output_file_path -- output file path that you will create\n","  '''\n","  with open(test_file_path, \"r\", encoding=\"utf-8\") as f:\n","    gold = f.read().splitlines()\n","  processed_translated = []\n","  for word in translated:\n","    curr_word = []\n","    for char in word:\n","      if char == \"<eow>\":\n","        break\n","      if char != \"<eow>\" and char != \"<pad>\":\n","        curr_word.append(char)\n","    processed_translated.append(curr_word)\n","  with open(output_file_path, \"w\", encoding=\"utf-8\") as fout:\n","    for g, t in zip(gold, processed_translated):\n","      fout.write(g + \"\\t\" + \" \".join(t) + \"\\n\")"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZkSBKV_C4dbd","executionInfo":{"status":"ok","timestamp":1625424373803,"user_tz":420,"elapsed":159,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["rum_test_path = data_path + \"rum_test.tsv\""],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"u4JurhKb4YYs","executionInfo":{"status":"ok","timestamp":1625424374829,"user_tz":420,"elapsed":161,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":["generate_final_prediction(rum_test_path, translated, root_path+\"predictions/rum_preds.tsv\")"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"W1u9-LsbqhtN","executionInfo":{"status":"ok","timestamp":1625424212053,"user_tz":420,"elapsed":7,"user":{"displayName":"Jeremy Zhang","photoUrl":"","userId":"07062043180576850316"}}},"source":[""],"execution_count":47,"outputs":[]}]}